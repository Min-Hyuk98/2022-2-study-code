{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from torchvision import datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.utils import save_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms_train = transforms.Compose([\n",
    "    transforms.Resize(28),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5], [0.5])\n",
    "])\n",
    "\n",
    "train_dataset = datasets.MNIST(root=\"./dataset\", train=True, download=True, transform=transforms_train)\n",
    "dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=128, shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = 100\n",
    "\n",
    "\n",
    "# 생성자(Generator) 클래스 정의\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "\n",
    "        # 하나의 블록(block) 정의\n",
    "        def block(input_dim, output_dim, normalize=True):\n",
    "            layers = [nn.Linear(input_dim, output_dim)]\n",
    "            if normalize:\n",
    "                # 배치 정규화(batch normalization) 수행(차원 동일)\n",
    "                layers.append(nn.BatchNorm1d(output_dim, 0.8))\n",
    "            layers.append(nn.LeakyReLU(0.2, inplace=True))\n",
    "            return layers\n",
    "\n",
    "        # 생성자 모델은 연속적인 여러 개의 블록을 가짐\n",
    "        self.model = nn.Sequential(\n",
    "            *block(latent_dim, 128, normalize=False),\n",
    "            *block(128, 256),\n",
    "            *block(256, 512),\n",
    "            *block(512, 1024),\n",
    "            nn.Linear(1024, 1 * 28 * 28),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, z):\n",
    "        img = self.model(z)\n",
    "        img = img.view(img.size(0), 1, 28, 28)\n",
    "        return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 판별자(Discriminator) 클래스 정의\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(1 * 28 * 28, 512),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(256, 1),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "    # 이미지에 대한 판별 결과를 반환\n",
    "    def forward(self, img):\n",
    "        flattened = img.view(img.size(0), -1)\n",
    "        output = self.model(flattened)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 생성자(generator)와 판별자(discriminator) 초기화\n",
    "generator = Generator()\n",
    "discriminator = Discriminator()\n",
    "\n",
    "generator.cuda()\n",
    "discriminator.cuda()\n",
    "\n",
    "# 손실 함수(loss function)\n",
    "adversarial_loss = nn.BCELoss()\n",
    "adversarial_loss.cuda()\n",
    "\n",
    "# 학습률(learning rate) 설정\n",
    "lr = 0.0002\n",
    "\n",
    "# 생성자와 판별자를 위한 최적화 함수\n",
    "optimizer_G = torch.optim.Adam(generator.parameters(), lr=lr, betas=(0.5, 0.999))\n",
    "optimizer_D = torch.optim.Adam(discriminator.parameters(), lr=lr, betas=(0.5, 0.999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0/80] [D loss: 0.486124] [G loss: 0.895796] [Elapsed time: 9.25s]\n",
      "[Epoch 1/80] [D loss: 0.444523] [G loss: 0.692690] [Elapsed time: 15.82s]\n",
      "[Epoch 2/80] [D loss: 0.320271] [G loss: 1.089620] [Elapsed time: 22.42s]\n",
      "[Epoch 3/80] [D loss: 0.170978] [G loss: 1.645630] [Elapsed time: 28.92s]\n",
      "[Epoch 4/80] [D loss: 0.359829] [G loss: 1.140320] [Elapsed time: 34.38s]\n",
      "[Epoch 5/80] [D loss: 0.201991] [G loss: 1.697496] [Elapsed time: 39.81s]\n",
      "[Epoch 6/80] [D loss: 0.298046] [G loss: 1.946994] [Elapsed time: 45.67s]\n",
      "[Epoch 7/80] [D loss: 0.197671] [G loss: 3.152655] [Elapsed time: 52.09s]\n",
      "[Epoch 8/80] [D loss: 0.344238] [G loss: 1.005469] [Elapsed time: 58.59s]\n",
      "[Epoch 9/80] [D loss: 0.292076] [G loss: 1.618618] [Elapsed time: 64.25s]\n",
      "[Epoch 10/80] [D loss: 0.290817] [G loss: 1.131984] [Elapsed time: 70.55s]\n",
      "[Epoch 11/80] [D loss: 0.495936] [G loss: 6.074459] [Elapsed time: 76.72s]\n",
      "[Epoch 12/80] [D loss: 0.160377] [G loss: 3.779373] [Elapsed time: 82.68s]\n",
      "[Epoch 13/80] [D loss: 0.119116] [G loss: 2.152084] [Elapsed time: 88.47s]\n",
      "[Epoch 14/80] [D loss: 0.171118] [G loss: 2.130270] [Elapsed time: 94.07s]\n",
      "[Epoch 15/80] [D loss: 0.197809] [G loss: 1.957506] [Elapsed time: 100.02s]\n",
      "[Epoch 16/80] [D loss: 0.377831] [G loss: 4.186526] [Elapsed time: 105.89s]\n",
      "[Epoch 17/80] [D loss: 0.284315] [G loss: 1.462177] [Elapsed time: 111.63s]\n",
      "[Epoch 18/80] [D loss: 0.267461] [G loss: 3.694252] [Elapsed time: 118.05s]\n",
      "[Epoch 19/80] [D loss: 0.296946] [G loss: 0.993048] [Elapsed time: 123.70s]\n",
      "[Epoch 20/80] [D loss: 0.351601] [G loss: 5.041572] [Elapsed time: 129.13s]\n",
      "[Epoch 21/80] [D loss: 0.379157] [G loss: 1.565898] [Elapsed time: 134.76s]\n",
      "[Epoch 22/80] [D loss: 0.204770] [G loss: 2.182726] [Elapsed time: 140.62s]\n",
      "[Epoch 23/80] [D loss: 0.249472] [G loss: 1.186031] [Elapsed time: 146.20s]\n",
      "[Epoch 24/80] [D loss: 0.123313] [G loss: 1.907158] [Elapsed time: 151.92s]\n",
      "[Epoch 25/80] [D loss: 0.761112] [G loss: 6.597112] [Elapsed time: 158.02s]\n",
      "[Epoch 26/80] [D loss: 0.106401] [G loss: 2.230209] [Elapsed time: 163.92s]\n",
      "[Epoch 27/80] [D loss: 0.159581] [G loss: 2.542995] [Elapsed time: 170.44s]\n",
      "[Epoch 28/80] [D loss: 0.146048] [G loss: 2.257243] [Elapsed time: 175.91s]\n",
      "[Epoch 29/80] [D loss: 0.145184] [G loss: 2.235386] [Elapsed time: 181.75s]\n",
      "[Epoch 30/80] [D loss: 0.142910] [G loss: 2.158601] [Elapsed time: 187.33s]\n",
      "[Epoch 31/80] [D loss: 0.121792] [G loss: 3.418574] [Elapsed time: 193.42s]\n",
      "[Epoch 32/80] [D loss: 1.133333] [G loss: 9.076490] [Elapsed time: 199.34s]\n",
      "[Epoch 33/80] [D loss: 0.125528] [G loss: 2.184727] [Elapsed time: 204.85s]\n",
      "[Epoch 34/80] [D loss: 0.138279] [G loss: 2.901318] [Elapsed time: 211.09s]\n",
      "[Epoch 35/80] [D loss: 0.091568] [G loss: 2.333505] [Elapsed time: 216.63s]\n",
      "[Epoch 36/80] [D loss: 0.093677] [G loss: 3.473393] [Elapsed time: 222.03s]\n",
      "[Epoch 37/80] [D loss: 0.336444] [G loss: 5.211993] [Elapsed time: 227.45s]\n",
      "[Epoch 38/80] [D loss: 0.201324] [G loss: 4.856028] [Elapsed time: 233.50s]\n",
      "[Epoch 39/80] [D loss: 0.201454] [G loss: 1.895646] [Elapsed time: 239.35s]\n",
      "[Epoch 40/80] [D loss: 0.182740] [G loss: 3.413599] [Elapsed time: 245.80s]\n",
      "[Epoch 41/80] [D loss: 0.151381] [G loss: 2.550888] [Elapsed time: 252.27s]\n",
      "[Epoch 42/80] [D loss: 0.156326] [G loss: 3.688981] [Elapsed time: 259.71s]\n",
      "[Epoch 43/80] [D loss: 0.132050] [G loss: 2.434017] [Elapsed time: 266.68s]\n",
      "[Epoch 44/80] [D loss: 0.130923] [G loss: 2.184500] [Elapsed time: 273.60s]\n",
      "[Epoch 45/80] [D loss: 0.170180] [G loss: 3.406932] [Elapsed time: 280.17s]\n",
      "[Epoch 46/80] [D loss: 0.214300] [G loss: 5.920275] [Elapsed time: 287.80s]\n",
      "[Epoch 47/80] [D loss: 0.136138] [G loss: 2.532784] [Elapsed time: 294.19s]\n",
      "[Epoch 48/80] [D loss: 0.202186] [G loss: 4.607254] [Elapsed time: 300.56s]\n",
      "[Epoch 49/80] [D loss: 0.288482] [G loss: 5.720174] [Elapsed time: 306.06s]\n",
      "[Epoch 50/80] [D loss: 0.218549] [G loss: 7.669346] [Elapsed time: 311.52s]\n",
      "[Epoch 51/80] [D loss: 0.138056] [G loss: 3.493202] [Elapsed time: 317.24s]\n",
      "[Epoch 52/80] [D loss: 0.167290] [G loss: 2.229817] [Elapsed time: 322.96s]\n",
      "[Epoch 53/80] [D loss: 0.082546] [G loss: 2.623943] [Elapsed time: 328.66s]\n",
      "[Epoch 54/80] [D loss: 0.159358] [G loss: 3.384561] [Elapsed time: 334.26s]\n",
      "[Epoch 55/80] [D loss: 0.194701] [G loss: 4.443197] [Elapsed time: 340.02s]\n",
      "[Epoch 56/80] [D loss: 0.106015] [G loss: 2.766441] [Elapsed time: 345.67s]\n",
      "[Epoch 57/80] [D loss: 0.061363] [G loss: 3.804493] [Elapsed time: 351.32s]\n",
      "[Epoch 58/80] [D loss: 0.098669] [G loss: 2.644558] [Elapsed time: 356.77s]\n",
      "[Epoch 59/80] [D loss: 0.470181] [G loss: 5.729696] [Elapsed time: 362.19s]\n",
      "[Epoch 60/80] [D loss: 0.237613] [G loss: 3.192052] [Elapsed time: 367.67s]\n",
      "[Epoch 61/80] [D loss: 0.158945] [G loss: 2.404786] [Elapsed time: 373.70s]\n",
      "[Epoch 62/80] [D loss: 1.394671] [G loss: 14.821143] [Elapsed time: 379.30s]\n",
      "[Epoch 63/80] [D loss: 0.108656] [G loss: 3.113449] [Elapsed time: 384.83s]\n",
      "[Epoch 64/80] [D loss: 0.090427] [G loss: 2.887615] [Elapsed time: 390.30s]\n",
      "[Epoch 65/80] [D loss: 0.168605] [G loss: 3.433485] [Elapsed time: 395.81s]\n",
      "[Epoch 66/80] [D loss: 0.156744] [G loss: 4.504413] [Elapsed time: 401.80s]\n",
      "[Epoch 67/80] [D loss: 0.108183] [G loss: 3.094288] [Elapsed time: 408.99s]\n",
      "[Epoch 68/80] [D loss: 0.135975] [G loss: 3.382102] [Elapsed time: 415.58s]\n",
      "[Epoch 69/80] [D loss: 0.137975] [G loss: 2.905551] [Elapsed time: 421.68s]\n",
      "[Epoch 70/80] [D loss: 0.130311] [G loss: 2.971799] [Elapsed time: 428.47s]\n",
      "[Epoch 71/80] [D loss: 0.109220] [G loss: 3.128292] [Elapsed time: 434.58s]\n",
      "[Epoch 72/80] [D loss: 0.147418] [G loss: 2.650166] [Elapsed time: 441.11s]\n",
      "[Epoch 73/80] [D loss: 0.281006] [G loss: 2.129670] [Elapsed time: 446.79s]\n",
      "[Epoch 74/80] [D loss: 0.237314] [G loss: 1.738082] [Elapsed time: 452.19s]\n",
      "[Epoch 75/80] [D loss: 0.147365] [G loss: 3.101292] [Elapsed time: 457.70s]\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "n_epochs = 80 # 학습의 횟수(epoch) 설정\n",
    "sample_interval = 2000 # 몇 번의 배치(batch)마다 결과를 출력할 것인지 설정\n",
    "start_time = time.time()\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    for i, (imgs, _) in enumerate(dataloader):\n",
    "\n",
    "        # 진짜(real) 이미지와 가짜(fake) 이미지에 대한 정답 레이블 생성\n",
    "        real = torch.cuda.FloatTensor(imgs.size(0), 1).fill_(1.0) # 진짜(real): 1\n",
    "        fake = torch.cuda.FloatTensor(imgs.size(0), 1).fill_(0.0) # 가짜(fake): 0\n",
    "\n",
    "        real_imgs = imgs.cuda()\n",
    "\n",
    "        \"\"\" 생성자(generator)를 학습합니다. \"\"\"\n",
    "        optimizer_G.zero_grad()\n",
    "\n",
    "        # 랜덤 노이즈(noise) 샘플링\n",
    "        z = torch.normal(mean=0, std=1, size=(imgs.shape[0], latent_dim)).cuda()\n",
    "\n",
    "        # 이미지 생성\n",
    "        generated_imgs = generator(z)\n",
    "\n",
    "        # 생성자(generator)의 손실(loss) 값 계산\n",
    "        g_loss = adversarial_loss(discriminator(generated_imgs), real)\n",
    "\n",
    "        # 생성자(generator) 업데이트\n",
    "        g_loss.backward()\n",
    "        optimizer_G.step()\n",
    "\n",
    "        \"\"\" 판별자(discriminator)를 학습합니다. \"\"\"\n",
    "        optimizer_D.zero_grad()\n",
    "\n",
    "        # 판별자(discriminator)의 손실(loss) 값 계산\n",
    "        real_loss = adversarial_loss(discriminator(real_imgs), real)\n",
    "        fake_loss = adversarial_loss(discriminator(generated_imgs.detach()), fake)\n",
    "        d_loss = (real_loss + fake_loss) / 2\n",
    "\n",
    "        # 판별자(discriminator) 업데이트\n",
    "        d_loss.backward()\n",
    "        optimizer_D.step()\n",
    "\n",
    "        done = epoch * len(dataloader) + i\n",
    "        if done % sample_interval == 0:\n",
    "            # 생성된 이미지 중에서 25개만 선택하여 5 X 5 격자 이미지에 출력\n",
    "            save_image(generated_imgs.data[:25], f\"{done}.png\", nrow=5, normalize=True)\n",
    "\n",
    "    # 하나의 epoch이 끝날 때마다 로그(log) 출력\n",
    "    print(f\"[Epoch {epoch}/{n_epochs}] [D loss: {d_loss.item():.6f}] [G loss: {g_loss.item():.6f}] [Elapsed time: {time.time() - start_time:.2f}s]\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "\n",
    "Image('92000.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
